{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T09:39:11.246832Z",
     "start_time": "2025-04-21T09:39:11.242298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip uninstall wikipedia-api\n",
    "# !pip install wikipedia\n"
   ],
   "id": "ad4da7b89abd9fc1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extracting sentences from Wikipedia in Romanian and generating handwriting images using different fonts.",
   "id": "2cd48199c50050b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T02:21:55.517943Z",
     "start_time": "2025-04-26T02:21:55.512434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import wikipedia\n",
    "import re\n",
    "import random\n",
    "\n",
    "# wikipedia.set_lang(\"ro\")\n",
    "\n",
    "topics = [\"Inteligență artificială\", \"România\", \"Baze de date\", \"Algoritm\", \"Rețea neuronală\",\" Procesare de limbaj natural\", \"Învățare automată\", \"Învățare profundă\", \"Recunoaștere a vorbirii\", \"Recunoaștere a imaginilor\", \"Robotica\", \"Sisteme expert\", \"Securitate cibernetică\", \"Internetul lucrurilor\", \"Blockchain\", \"Big data\"]\n",
    "len(topics)"
   ],
   "id": "4c82b6507b1bfceb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "sentences = []\n",
    "\n",
    "for topic in topics:\n",
    "    try:\n",
    "        content = wikipedia.page(topic).content\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        content = wikipedia.page(e.options[0]).content\n",
    "    except Exception as e:\n",
    "        print(f\"Skip {topic}: {e}\")\n",
    "        continue\n",
    "\n",
    "    raw = re.split(r'(?<=[.!?])\\s+', content)\n",
    "    for s in raw:\n",
    "        s = s.strip()\n",
    "        if 30 < len(s) < 150 and all(c.isprintable() for c in s):\n",
    "            sentences.append(s)\n",
    "\n",
    "selected = random.sample(sentences, k=min(1000, len(sentences)))\n",
    "\n",
    "with open(\"propozitii_ro.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for s in selected:\n",
    "        f.write(s + \"\\n\")\n",
    "\n",
    "print(f\"I have extracted {len(selected)} sentences from Wikipedia.\")\n"
   ],
   "id": "6e3d679be8606fb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generating handwriting images using different fonts.",
   "id": "8d39f6dffb92dc1e"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T19:10:19.571265Z",
     "start_time": "2025-04-21T19:08:40.593735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pandas as pd\n",
    "import os\n",
    "import textwrap\n",
    "import glob\n",
    "\n",
    "\n",
    "input_file = \"propozitii_ro.txt\"\n",
    "font_dir = \"fonts\" # fonts that will be used to generate handwriting\n",
    "output_dir = \"handwriting_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# load sentences\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# load fonts\n",
    "font_files = glob.glob(os.path.join(font_dir, \"*.ttf\"))\n",
    "if not font_files:\n",
    "    raise ValueError(\" Did not find fonts in  'fonts/'\")\n",
    "\n",
    "# generate images\n",
    "records = []\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for font_path in font_files:\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, 32)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Couldn't load font {font_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        wrapped = textwrap.fill(sentence, width=40)\n",
    "        img = Image.new(\"RGB\", (800, 120), \"white\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.text((10, 10), wrapped, font=font, fill=\"black\")\n",
    "\n",
    "        font_name = os.path.basename(font_path).split('.')[0]\n",
    "        base_name = f\"line_{i}_{font_name}\"\n",
    "        img_path = os.path.join(output_dir, f\"{base_name}.png\")\n",
    "        txt_path = os.path.join(output_dir, f\"{base_name}.txt\")\n",
    "\n",
    "        img.save(img_path)\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(sentence)\n",
    "\n",
    "        records.append({\"image\": img_path, \"text\": sentence})\n",
    "\n",
    "# === Export .csv pentru pairing\n",
    "csv_path = os.path.join(output_dir, \"dataset_info.csv\")\n",
    "pd.DataFrame(records).to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"I have generated {len(records)} images.\")\n",
    "print(f\"CSV: {csv_path}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have generated 11304 images.\n",
      "CSV: handwriting_dataset\\dataset_info.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T19:12:12.184Z",
     "start_time": "2025-04-21T19:10:59.171809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# config\n",
    "input_dir = \"handwriting_dataset\"\n",
    "output_dir = \"handwriting_dataset_augmented\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "image_paths = glob.glob(os.path.join(input_dir, \"*.png\"))\n",
    "\n",
    "def augment_image(img):\n",
    "    # we rotate the image by a random angle\n",
    "    angle = random.uniform(-5, 5)\n",
    "    img = img.rotate(angle, expand=True, fillcolor=\"white\")\n",
    "\n",
    "    # brightness\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(random.uniform(0.85, 1.15))\n",
    "\n",
    "    # blur\n",
    "    if random.random() < 0.4:\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.3, 1.0)))\n",
    "\n",
    "    # noise\n",
    "    pixels = img.load()\n",
    "    for _ in range(random.randint(150, 400)):\n",
    "        x = random.randint(0, img.size[0] - 1)\n",
    "        y = random.randint(0, img.size[1] - 1)\n",
    "        color = (0, 0, 0) if random.random() < 0.5 else (255, 255, 255)\n",
    "        pixels[x, y] = color\n",
    "\n",
    "    return img\n",
    "\n",
    "# augment images\n",
    "for path in image_paths:\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    aug_img = augment_image(img)\n",
    "\n",
    "    base_name = os.path.basename(path).replace(\".png\", \"_aug.png\")\n",
    "    aug_img.save(os.path.join(output_dir, base_name))\n",
    "\n",
    "print(f\"Augmented images saved in: {output_dir}\")\n"
   ],
   "id": "21e989f8eb5a70a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images saved in: handwriting_dataset_augmented\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T19:12:44.912416Z",
     "start_time": "2025-04-21T19:12:22.467085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "original_dir = \"handwriting_dataset\"\n",
    "augmented_dir = \"handwriting_dataset_augmented\"\n",
    "original_csv = os.path.join(original_dir, \"dataset_info.csv\")\n",
    "output_csv = \"handwriting_dataset_full.csv\"\n",
    "\n",
    "# read original dataset\n",
    "df_original = pd.read_csv(original_csv)\n",
    "df_original[\"augmented\"] = False\n",
    "\n",
    "# read augmented dataset\n",
    "df_augmented = df_original.copy()\n",
    "df_augmented[\"image\"] = df_augmented[\"image\"].apply(\n",
    "    lambda path: os.path.join(augmented_dir, os.path.basename(path).replace(\".png\", \"_aug.png\"))\n",
    ")\n",
    "df_augmented[\"augmented\"] = True\n",
    "\n",
    "# combine datasets\n",
    "df_full = pd.concat([df_original, df_augmented], ignore_index=True)\n",
    "\n",
    "# save combined dataset\n",
    "df_full.to_csv(output_csv, index=False)\n",
    "# save to a combined folder\n",
    "combined_dir = \"handwriting_dataset_ro\"\n",
    "os.makedirs(combined_dir, exist_ok=True)\n",
    "for _, row in df_full.iterrows():\n",
    "    src = row[\"image\"]\n",
    "    dst = os.path.join(combined_dir, os.path.basename(src))\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.copy2(src, dst)\n",
    "print(f\"Combined dataset saved in: {combined_dir}\")\n",
    "print(f\"Combined dataset saved in: {output_csv}\")\n",
    "print(f\"Total images: {len(df_full)}\")\n"
   ],
   "id": "852b22794c634ffa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved in: handwriting_dataset_ro\n",
      "Combined dataset saved in: handwriting_dataset_full.csv\n",
      "Total images: 22608\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
